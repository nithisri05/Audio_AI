## Audio Foundations for Voice AI

This repository contains two Jupyter notebooks that cover the core audio processing fundamentals required for building Voice AI and Automatic Speech Recognition (ASR) systems.

## Contents
```.
├── Audio_Basics_&_Visualization.ipynb
├── Audio_Preprocessing_&_Augmentation.ipynb
└── README.md
```
## Audio Basics & Visualization

**Purpose:**
Introduces how raw audio is represented and transformed for speech processing.

**Covers:**

* Audio waveforms (time domain)

* Frequency analysis (FFT, spectrogram)

* Mel-spectrograms

* MFCC feature extraction
**Outcome:**
Builds a clear understanding of audio representations used in legacy and modern ASR systems.

## Audio Preprocessing & Augmentation

**Purpose:**
Demonstrates techniques to prepare and strengthen speech data for real-world ASR.

**Covers:**

* Audio preprocessing

* Noise-based augmentation

* Visualization and comparison

* ASR robustness evaluation

**Outcome:**
Highlights the importance of preprocessing and augmentation for building reliable Voice AI systems.

**Key Takeaway**
Raw Audio → Features → Preprocessing → ASR-Ready Data


These notebooks form the foundation layer before exploring modern ASR architectures such as CTC, Transducers, and Speech LLMs.

## Tech Stack

* Python

* Librosa

* NumPy

* Matplotlib

* SoundFile
