{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "This notebook focuses on a**udio preprocessing and augmentation techniques** used to make ASR systems robust to noise, variation, and real-world conditions.\n",
        "\n",
        "The goal is to simulate real-world speech variations and observe how preprocessing affects recognition.\n",
        "\n",
        "## What this notebook contains\n",
        "\n",
        "* Loading and visualizing audio\n",
        "\n",
        "* Helper functions for plotting\n",
        "\n",
        "* Audio augmentation techniques\n",
        "\n",
        "* Saving augmented audio\n",
        "\n",
        "* Comparing ASR performance"
      ],
      "metadata": {
        "id": "g44PlBo3COVJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Load an Audio File"
      ],
      "metadata": {
        "id": "kRtnjJDlAwM7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8e9hGzXACTO"
      },
      "outputs": [],
      "source": [
        "import librosa, librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Use built-in example or upload your own audio\n",
        "file_path =\"/content/jewellery_audio.wav\"\n",
        "y, sr = librosa.load(file_path, sr=16000)  # force 16kHz for ASR\n",
        "\n",
        "print(f\"Original audio: {'/content/NoteGPT_Speech_1757675744872.wav'}, Duration: {len(y)/sr:.2f}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Helper Function for Visualization"
      ],
      "metadata": {
        "id": "KbxWtoHeBGon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_waveform(y, sr, title=\"Waveform\"):\n",
        "    plt.figure(figsize=(12, 3))\n",
        "    librosa.display.waveshow(y, sr=sr)\n",
        "    plt.title(title)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "LjAm1zOOBHjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Apply Augmentations"
      ],
      "metadata": {
        "id": "5Orwto1vBMxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (a) Add Noise\n",
        "noise = 0.005 * np.random.randn(len(y))\n",
        "y_noise = y + noise\n",
        "\n",
        "# (b) Pitch Shift (up by 2 semitones)\n",
        "y_pitch = librosa.effects.pitch_shift(y, sr=sr, n_steps=2)\n",
        "\n",
        "# (c) Time Stretch (slower by 1.25x)\n",
        "y_stretch = librosa.effects.time_stretch(y, rate=0.8)\n",
        "\n",
        "# Plot all versions\n",
        "plot_waveform(y, sr, \"Original\")\n",
        "plot_waveform(y_noise, sr, \"With Noise\")\n",
        "plot_waveform(y_pitch, sr, \"Pitch Shifted (+2 semitones)\")\n",
        "plot_waveform(y_stretch, sr, \"Time Stretched (Slower)\")"
      ],
      "metadata": {
        "id": "xVFrQC9gBN5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Save Augmented Audio"
      ],
      "metadata": {
        "id": "hc3jZHB8BagQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import soundfile as sf\n",
        "\n",
        "sf.write(\"original.wav\", y, sr)\n",
        "sf.write(\"noise.wav\", y_noise, sr)\n",
        "sf.write(\"pitch.wav\", y_pitch, sr)\n",
        "sf.write(\"stretch.wav\", y_stretch, sr)\n",
        "\n",
        "print(\"Audio files saved: original.wav, noise.wav, pitch.wav, stretch.wav\")"
      ],
      "metadata": {
        "id": "F3pwC_r3BWxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Compare with ASR (Whisper API)"
      ],
      "metadata": {
        "id": "s4RbiyLpBmLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")\n",
        "OPENAI_BASE_URL = userdata.get(\"OPENAI_BASE_URL\")\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=OPENAI_API_KEY,\n",
        "    base_url=OPENAI_BASE_URL\n",
        ")\n"
      ],
      "metadata": {
        "id": "qSAyNWK54ab5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "\n",
        "def transcribe_audio(file_path):\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        response = client.audio.transcriptions.create(\n",
        "            model=\"whisper-1\",\n",
        "            file=f\n",
        "        )\n",
        "    print(response)\n",
        "    return response.text\n",
        "\n",
        "# Run ASR on original vs augmented audio\n",
        "print(\"Original:\", transcribe_audio(\"original.wav\"))\n",
        "print(\"With Noise:\", transcribe_audio(\"noise.wav\"))\n",
        "print(\"Pitch Shifted:\", transcribe_audio(\"pitch.wav\"))\n",
        "print(\"Time Stretched:\", transcribe_audio(\"stretch.wav\"))"
      ],
      "metadata": {
        "id": "Qe6qIAoLBnbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Observation â€“ Audio Preprocessing & Augmentation\n",
        "\n",
        "This notebook illustrates the role of audio preprocessing and augmentation in improving the robustness of speech data for real-world applications. By applying techniques such as noise addition and visual comparison of original and augmented audio, it shows how speech signals can be modified while preserving essential linguistic content. The notebook highlights that preprocessing improves audio quality and augmentation increases data diversity, helping speech recognition systems generalize better under varying environmental conditions. Overall, it emphasizes that preprocessing and augmentation are critical steps for building reliable and production-ready Voice AI systems."
      ],
      "metadata": {
        "id": "-zViFj5yCucD"
      }
    }
  ]
}