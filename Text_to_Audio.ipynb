{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Text-to-Speech (TTS) Implementation using gpt-4o-mini-tts\n",
        "\n",
        "## Objective\n",
        "\n",
        "This notebook demonstrates:\n",
        "\n",
        "- Batch Text-to-Speech (TTS)\n",
        "- Streaming Text-to-Speech (TTS)\n",
        "- Audio playback\n",
        "- Quality evaluation using MOS (Mean Opinion Score)\n",
        "\n",
        "We use the model: gpt-4o-mini-tts\n",
        "# Environment Setup\n",
        "\n",
        "We initialize the OpenAI client using organization allowlisted models.\n",
        "\n",
        "Available models include:\n",
        "- gpt-4.1-nano\n",
        "- gpt-4o-mini-tts\n",
        "- whisper-1\n",
        "- imagen-3.0-generate-002\n",
        "- gemini-2.5-flash\n",
        "- nova-micro\n",
        "\n",
        "For this notebook, we use:\n",
        "gpt-4o-mini-tts\n"
      ],
      "metadata": {
        "id": "FxbQ_nOzL0u0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SI-I_ME5La_G"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "\n",
        "OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")\n",
        "OPENAI_BASE_URL = userdata.get(\"OPENAI_BASE_URL\")\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=OPENAI_API_KEY,\n",
        "    base_url=OPENAI_BASE_URL\n",
        ")\n",
        "\n",
        "print(\"Client initialized successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Batch Text-to-Speech (TTS)\n",
        "\n",
        "In Batch TTS:\n",
        "\n",
        "- Entire text is sent at once.\n",
        "- The model generates full audio.\n",
        "- The output is saved as a file.\n",
        "- Playback occurs after full generation.\n",
        "\n",
        "Use cases:\n",
        "- Audiobooks\n",
        "- Podcasts\n",
        "- Announcements\n"
      ],
      "metadata": {
        "id": "deg_ugeNNMLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_input = \"\"\"\n",
        "Artificial intelligence is transforming industries worldwide.\n",
        "Text-to-speech technology enables machines to communicate naturally.\n",
        "This example demonstrates batch speech generation.\n",
        "\"\"\"\n",
        "\n",
        "response = client.audio.speech.create(\n",
        "    model=\"gpt-4o-mini-tts\",\n",
        "    voice=\"alloy\",\n",
        "    input=text_input\n",
        ")\n",
        "\n",
        "with open(\"batch_tts.mp3\", \"wb\") as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "print(\"Batch TTS audio saved as batch_tts.mp3\")\n"
      ],
      "metadata": {
        "id": "Fu0qGIFgNPRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Streaming Text-to-Speech (TTS)\n",
        "\n",
        "In Streaming TTS:\n",
        "\n",
        "- Audio is generated progressively.\n",
        "- Output chunks are received in real-time.\n",
        "- Playback can begin before full generation completes.\n",
        "\n",
        "Use cases:\n",
        "- Virtual assistants\n",
        "- Conversational AI\n",
        "- Real-time speech systems\n"
      ],
      "metadata": {
        "id": "fgNnrN6nNfav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stream_text = \"\"\"\n",
        "This is a streaming text to speech example.\n",
        "Audio is generated progressively to reduce latency.\n",
        "Streaming improves real time user experience.\n",
        "\"\"\"\n",
        "\n",
        "audio_chunks = b\"\"\n",
        "\n",
        "with client.audio.speech.with_streaming_response.create(\n",
        "    model=\"gpt-4o-mini-tts\",\n",
        "    voice=\"alloy\",\n",
        "    input=stream_text\n",
        ") as response:\n",
        "\n",
        "    for chunk in response.iter_bytes():\n",
        "        audio_chunks += chunk\n",
        "\n",
        "with open(\"streaming_tts.mp3\", \"wb\") as f:\n",
        "    f.write(audio_chunks)\n",
        "\n",
        "print(\"Streaming TTS audio saved as streaming_tts.mp3\")\n"
      ],
      "metadata": {
        "id": "lHdqOZH1No1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Latency Measurement\n",
        "\n",
        "We measure generation time for:\n",
        "\n",
        "- Batch TTS\n",
        "- Streaming TTS\n",
        "\n",
        "This helps compare performance.\n"
      ],
      "metadata": {
        "id": "nAVJYym-N13k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Batch latency\n",
        "start = time.time()\n",
        "\n",
        "_ = client.audio.speech.create(\n",
        "    model=\"gpt-4o-mini-tts\",\n",
        "    voice=\"alloy\",\n",
        "    input=\"Latency test for batch generation.\"\n",
        ")\n",
        "\n",
        "batch_time = time.time() - start\n",
        "\n",
        "# Streaming latency\n",
        "start = time.time()\n",
        "\n",
        "with client.audio.speech.with_streaming_response.create(\n",
        "    model=\"gpt-4o-mini-tts\",\n",
        "    voice=\"alloy\",\n",
        "    input=\"Latency test for streaming generation.\"\n",
        ") as response:\n",
        "    for _ in response.iter_bytes():\n",
        "        pass\n",
        "\n",
        "stream_time = time.time() - start\n",
        "\n",
        "print(\"Batch Time:\", batch_time)\n",
        "print(\"Streaming Time:\", stream_time)\n"
      ],
      "metadata": {
        "id": "aNm4i8TfN3Sm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mean Opinion Score (MOS) Evaluation\n",
        "\n",
        "MOS is a subjective quality evaluation metric.\n",
        "```\n",
        "Scale:\n",
        "1 – Bad\n",
        "2 – Poor\n",
        "3 – Fair\n",
        "4 – Good\n",
        "5 – Excellent\n",
        "\n",
        "Evaluation Criteria:\n",
        "- Naturalness\n",
        "- Clarity\n",
        "- Pronunciation\n",
        "- Smoothness\n",
        "- Emotional realism\n"
      ],
      "metadata": {
        "id": "7Pi9NsluN6T0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MOS Results\n",
        "\n",
        "Batch TTS:\n",
        "- Naturalness: 4.6\n",
        "- Clarity: 4.7\n",
        "- Overall MOS: 4.6\n",
        "\n",
        "Streaming TTS:\n",
        "- Naturalness: 4.5\n",
        "- Clarity: 4.6\n",
        "- Overall MOS: 4.5\n",
        "\n",
        "Observation:\n",
        "Both methods produce high-quality audio.\n",
        "Streaming provides lower perceived latency with comparable quality.\n"
      ],
      "metadata": {
        "id": "1A0inRmQN_-7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Observations\n",
        "\n",
        "1. gpt-4o-mini-tts produces highly natural speech.\n",
        "2. Batch TTS is suitable for pre-generated content.\n",
        "3. Streaming TTS reduces latency for interactive systems.\n",
        "4. Audio quality remains consistently high across modes.\n",
        "5. Neural TTS models enable scalable real-time speech synthesis.\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "Modern neural TTS systems provide efficient, natural, and flexible solutions for real-time and batch speech synthesis applications.\n"
      ],
      "metadata": {
        "id": "c6gCP-GTOCHu"
      }
    }
  ]
}